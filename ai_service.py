"""
AIèŠå¤©æœåŠ¡ - æ”¯æŒå¤šç§AIæœåŠ¡æä¾›å•†
"""
import requests
from typing import List, Dict
from config import (
    AI_PROVIDER,
    OPENAI_API_KEY, OPENAI_API_BASE_URL, OPENAI_MODEL_NAME,
    OLLAMA_BASE_URL, OLLAMA_MODEL_NAME,
    GEMINI_API_KEY, GEMINI_MODEL_NAME,
    CLAUDE_API_KEY, CLAUDE_MODEL_NAME,
    AI_GIRLFRIEND_SYSTEM_PROMPT
)
from database import SessionLocal, Conversation
from datetime import datetime

class AIChatService:
    def __init__(self):
        self.provider = AI_PROVIDER
        self.client = None
        
        print(f"ğŸ¤– ä½¿ç”¨AIæœåŠ¡æä¾›å•†: {self.provider}")
        
        if self.provider == "ollama":
            self._init_ollama()
        elif self.provider == "openai":
            self._init_openai()
        elif self.provider == "gemini":
            self._init_gemini()
        elif self.provider == "claude":
            self._init_claude()
        else:
            print(f"âš ï¸  æœªçŸ¥çš„AIæœåŠ¡æä¾›å•†: {self.provider}")
            print("   å°†ä½¿ç”¨æ¨¡æ‹Ÿå›å¤æ¨¡å¼")
            self.client = None
    
    def _init_openai(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI
            if OPENAI_API_KEY and OPENAI_API_KEY.strip() and OPENAI_API_KEY != "your_openai_api_key_here":
                if OPENAI_API_BASE_URL and OPENAI_API_BASE_URL != "https://api.openai.com/v1":
                    self.client = OpenAI(api_key=OPENAI_API_KEY.strip(), base_url=OPENAI_API_BASE_URL)
                else:
                    self.client = OpenAI(api_key=OPENAI_API_KEY.strip())
                print(f"âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {OPENAI_MODEL_NAME}")
            else:
                print("âš ï¸  æœªè®¾ç½®OPENAI_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå›å¤")
                self.client = None
        except ImportError:
            print("âš ï¸  æœªå®‰è£…openaiåº“ï¼Œè¯·è¿è¡Œ: pip install openai")
            self.client = None
        except Exception as e:
            print(f"âš ï¸  OpenAIåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.client = None
    
    def _init_ollama(self):
        """åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯ï¼ˆå…è´¹æœ¬åœ°æ¨¡å‹ï¼‰"""
        try:
            # æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=3)
            if response.status_code == 200:
                self.client = "ollama"
                print(f"âœ… OllamaæœåŠ¡è¿æ¥æˆåŠŸï¼Œæ¨¡å‹: {OLLAMA_MODEL_NAME}")
                print(f"ğŸ“ Ollamaåœ°å€: {OLLAMA_BASE_URL}")
                
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
                models = response.json().get("models", [])
                model_names = [m.get("name", "") for m in models]
                if OLLAMA_MODEL_NAME not in model_names:
                    print(f"âš ï¸  æ¨¡å‹ {OLLAMA_MODEL_NAME} æœªæ‰¾åˆ°")
                    print(f"   å¯ç”¨æ¨¡å‹: {', '.join(model_names[:5])}")
                    print(f"   è¯·è¿è¡Œ: ollama pull {OLLAMA_MODEL_NAME}")
            else:
                print(f"âš ï¸  OllamaæœåŠ¡ä¸å¯ç”¨ (çŠ¶æ€ç : {response.status_code})")
                print(f"   è¯·ç¡®ä¿Ollamaå·²å®‰è£…å¹¶è¿è¡Œ")
                print(f"   å®‰è£…: https://ollama.ai")
                self.client = None
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸  æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡: {str(e)}")
            print(f"   è¯·ç¡®ä¿Ollamaå·²å®‰è£…å¹¶è¿è¡Œåœ¨ {OLLAMA_BASE_URL}")
            print(f"   å®‰è£…æŒ‡å—: https://ollama.ai")
            self.client = None
    
    def _init_gemini(self):
        """åˆå§‹åŒ–Google Geminiå®¢æˆ·ç«¯"""
        try:
            if GEMINI_API_KEY and GEMINI_API_KEY.strip():
                self.client = "gemini"
                print(f"âœ… Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {GEMINI_MODEL_NAME}")
            else:
                print("âš ï¸  æœªè®¾ç½®GEMINI_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå›å¤")
                self.client = None
        except Exception as e:
            print(f"âš ï¸  Geminiåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.client = None
    
    def _init_claude(self):
        """åˆå§‹åŒ–Anthropic Claudeå®¢æˆ·ç«¯"""
        try:
            if CLAUDE_API_KEY and CLAUDE_API_KEY.strip():
                self.client = "claude"
                print(f"âœ… Claudeå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {CLAUDE_MODEL_NAME}")
            else:
                print("âš ï¸  æœªè®¾ç½®CLAUDE_API_KEYï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿå›å¤")
                self.client = None
        except Exception as e:
            print(f"âš ï¸  Claudeåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.client = None
    
    def get_chat_response(self, user_message: str, user_id: str, conversation_history: list = None):
        """è·å–AIå›å¤"""
        if self.client is None:
            return self._get_mock_response(user_message)
        
        try:
            if self.provider == "ollama":
                return self._get_ollama_response(user_message, user_id, conversation_history)
            elif self.provider == "openai":
                return self._get_openai_response(user_message, user_id, conversation_history)
            elif self.provider == "gemini":
                return self._get_gemini_response(user_message, user_id, conversation_history)
            elif self.provider == "claude":
                return self._get_claude_response(user_message, user_id, conversation_history)
            else:
                return self._get_mock_response(user_message)
        except Exception as e:
            print(f"AIæœåŠ¡é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹ç´¯äº†ï¼Œèƒ½ç¨åå†èŠå—ï¼ŸğŸ˜Š"
    
    def _get_ollama_response(self, user_message: str, user_id: str, conversation_history: list = None):
        """ä½¿ç”¨Ollamaè·å–å›å¤ï¼ˆå…è´¹æœ¬åœ°æ¨¡å‹ï¼‰"""
        # ä½¿ç”¨Ollamaçš„chat APIï¼ˆæ¨èæ–¹å¼ï¼‰
        messages = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤º
        messages.append({"role": "system", "content": AI_GIRLFRIEND_SYSTEM_PROMPT})
        
        # æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘çš„10æ¡ï¼‰
        if conversation_history:
            for conv in conversation_history[-10:]:
                messages.append({"role": "user", "content": conv.message})
                messages.append({"role": "assistant", "content": conv.response})
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        # ä½¿ç”¨Ollamaçš„chat API
        response = requests.post(
            f"{OLLAMA_BASE_URL}/api/chat",
            json={
                "model": OLLAMA_MODEL_NAME,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": 0.8,
                    "num_predict": 500
                }
            },
            timeout=120  # Ollamaå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result.get("message", {}).get("content", "")
            if not ai_response:
                # å¦‚æœchat APIå¤±è´¥ï¼Œå°è¯•generate API
                return self._get_ollama_generate_response(user_message, user_id, conversation_history)
            self._save_conversation(user_id, user_message, ai_response)
            return ai_response
        else:
            # å¦‚æœchat APIå¤±è´¥ï¼Œå°è¯•generate API
            try:
                return self._get_ollama_generate_response(user_message, user_id, conversation_history)
            except Exception as e:
                raise Exception(f"Ollama APIé”™è¯¯: {response.status_code} - {response.text}")
    
    def _get_ollama_generate_response(self, user_message: str, user_id: str, conversation_history: list = None):
        """ä½¿ç”¨Ollamaçš„generate APIï¼ˆå¤‡ç”¨æ–¹å¼ï¼‰"""
        # æ„å»ºæç¤ºæ–‡æœ¬
        prompt_parts = [AI_GIRLFRIEND_SYSTEM_PROMPT, "\n\n"]
        
        # æ·»åŠ å¯¹è¯å†å²
        if conversation_history:
            for conv in conversation_history[-10:]:
                prompt_parts.append(f"ç”¨æˆ·: {conv.message}\n")
                prompt_parts.append(f"åŠ©æ‰‹: {conv.response}\n\n")
        
        # æ·»åŠ å½“å‰æ¶ˆæ¯
        prompt_parts.append(f"ç”¨æˆ·: {user_message}\n")
        prompt_parts.append("åŠ©æ‰‹: ")
        
        prompt = "".join(prompt_parts)
        
        response = requests.post(
            f"{OLLAMA_BASE_URL}/api/generate",
            json={
                "model": OLLAMA_MODEL_NAME,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.8,
                    "num_predict": 500
                }
            },
            timeout=120
        )
        
        if response.status_code == 200:
            ai_response = response.json().get("response", "").strip()
            self._save_conversation(user_id, user_message, ai_response)
            return ai_response
        else:
            raise Exception(f"Ollama APIé”™è¯¯: {response.status_code} - {response.text}")
    
    def _get_openai_response(self, user_message: str, user_id: str, conversation_history: list = None):
        """ä½¿ç”¨OpenAIè·å–å›å¤"""
        # æ„å»ºæ¶ˆæ¯å†å²
        messages = [{"role": "system", "content": AI_GIRLFRIEND_SYSTEM_PROMPT}]
        
        # æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘çš„10æ¡ï¼‰
        if conversation_history:
            for conv in conversation_history[-10:]:
                messages.append({"role": "user", "content": conv.message})
                messages.append({"role": "assistant", "content": conv.response})
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        # è°ƒç”¨OpenAI API
        response = self.client.chat.completions.create(
            model=OPENAI_MODEL_NAME,
            messages=messages,
            temperature=0.8,
            max_tokens=500
        )
        
        ai_response = response.choices[0].message.content
        self._save_conversation(user_id, user_message, ai_response)
        return ai_response
    
    def _get_gemini_response(self, user_message: str, user_id: str, conversation_history: list = None):
        """ä½¿ç”¨Google Geminiè·å–å›å¤"""
        try:
            import google.generativeai as genai
            genai.configure(api_key=GEMINI_API_KEY)
            model = genai.GenerativeModel(GEMINI_MODEL_NAME)
            
            # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
            context = AI_GIRLFRIEND_SYSTEM_PROMPT + "\n\n"
            if conversation_history:
                for conv in conversation_history[-10:]:
                    context += f"ç”¨æˆ·: {conv.message}\nAI: {conv.response}\n\n"
            
            context += f"ç”¨æˆ·: {user_message}\nAI: "
            
            response = model.generate_content(context)
            ai_response = response.text
            self._save_conversation(user_id, user_message, ai_response)
            return ai_response
        except ImportError:
            raise Exception("è¯·å®‰è£…Google Geminiåº“: pip install google-generativeai")
    
    def _get_claude_response(self, user_message: str, user_id: str, conversation_history: list = None):
        """ä½¿ç”¨Anthropic Claudeè·å–å›å¤"""
        try:
            from anthropic import Anthropic
            client = Anthropic(api_key=CLAUDE_API_KEY)
            
            # æ„å»ºæ¶ˆæ¯å†å²
            messages = []
            if conversation_history:
                for conv in conversation_history[-10:]:
                    messages.append({"role": "user", "content": conv.message})
                    messages.append({"role": "assistant", "content": conv.response})
            messages.append({"role": "user", "content": user_message})
            
            response = client.messages.create(
                model=CLAUDE_MODEL_NAME,
                max_tokens=500,
                temperature=0.8,
                system=AI_GIRLFRIEND_SYSTEM_PROMPT,
                messages=messages
            )
            
            ai_response = response.content[0].text
            self._save_conversation(user_id, user_message, ai_response)
            return ai_response
        except ImportError:
            raise Exception("è¯·å®‰è£…Anthropicåº“: pip install anthropic")
    
    
    def _save_conversation(self, user_id: str, user_message: str, ai_response: str):
        """ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“"""
        try:
            db = SessionLocal()
            conversation = Conversation(
                user_id=user_id,
                message=user_message,
                response=ai_response,
                created_at=datetime.utcnow()
            )
            db.add(conversation)
            db.commit()
            db.close()
        except Exception as e:
            print(f"ä¿å­˜å¯¹è¯å¤±è´¥: {str(e)}")
    
    def _get_mock_response(self, user_message: str):
        """æ¨¡æ‹Ÿå›å¤ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        mock_responses = [
            "å—¯å—¯ï¼Œæˆ‘åœ¨å¬å‘¢~ ä½ æƒ³è¯´ä»€ä¹ˆï¼Ÿ",
            "çœŸçš„å—ï¼Ÿå¥½æœ‰è¶£ï¼ç»§ç»­è¯´è¯´çœ‹ ğŸ˜Š",
            "æˆ‘ä¹Ÿè¿™ä¹ˆè§‰å¾—å‘¢ï¼",
            "å“ˆå“ˆå“ˆï¼Œä½ è¯´è¯çœŸæœ‰æ„æ€~",
            "æˆ‘ç†è§£ä½ çš„æ„Ÿå—ï¼ŒæŠ±æŠ±~ ğŸ’•"
        ]
        import random
        return random.choice(mock_responses)
    
    def get_conversation_history(self, user_id: str, limit: int = 20):
        """è·å–ç”¨æˆ·å¯¹è¯å†å²"""
        try:
            db = SessionLocal()
            conversations = db.query(Conversation).filter(
                Conversation.user_id == user_id
            ).order_by(Conversation.created_at.desc()).limit(limit).all()
            db.close()
            return list(reversed(conversations))  # è¿”å›æ­£åº
        except Exception as e:
            print(f"è·å–å¯¹è¯å†å²å¤±è´¥: {str(e)}")
            return []
